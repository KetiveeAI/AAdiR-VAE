training:
    batch_size: 16         # Optimized for memory/performance balance
    epochs: 350           # Extended training for better convergence
    learning_rate: 0.0001
    gradient_accumulation_steps: 4  # Effective batch size = 64
    save_interval: 5
    resume_checkpoint: "checkpoints/lite_model_epoch_189.pth"
    use_amp: true         # Mixed precision training
    grad_clip: 1.0
    log_interval: 10      # Log every 10 steps
    track_time: true      # Enable epoch time tracking
    save_logs: true       # Save training logs to file

model:
    image_size: 128       # Fixed size
    text_embed_dim: 768
    image_channels: 3
    latent_dim: 32       # Reduced dimension

data:
    image_size: 128      # Match model size
    max_seq_length: 128
    dataset_path: "data/images"
    max_images: 34000    # Increased dataset size for better training